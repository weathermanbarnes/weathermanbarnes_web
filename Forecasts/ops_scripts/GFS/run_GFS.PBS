#!/bin/bash

data_download=true
run_plotting=true
copy_to_bucket=true

#export date=20240526
export date=$(date -d "yesterday" +"%Y%m%d")
export run=12
export nciproj="gb02"
export username="mb0427"
export outpath="/scratch/"${nciproj}"/"${username}"/Website/Forecasts/NOAA/GFS/"
export runpath="/g/data/"${nciproj}"/"${username}"/Website/Forecasts/ops_scripts/GFS/"

echo ${date} ${run}

rm -f "${outpath}"*.check

rm -rf "${runpath}output/"get_GFS*.e
rm -rf "${runpath}output/"get_GFS*.o
rm -rf "${runpath}output/"plot_GFS*.e
rm -rf "${runpath}output/"plot_GFS*.o
rm -rf "${runpath}output/"copy_GFS*.e
rm -rf "${runpath}output/"copy_GFS*.o

RANGE=$(seq -2 10)
plotRANGE=$(seq -42 6 240)

if [ "$data_download" = true ]; then
    
    rm -f "${outpath}data/"*.grib2
    rm -f "${outpath}data/"*.idx

    # Use the range in a loop
    for day in $RANGE;
    do
        # set the job name
        NAME="get_GFS-d"${day}
        echo "Submitting: ${NAME}"
    
        # Build a string called PBS which contains the instructions for your run
        # This requests 1 node for 1 hour. Runs a program called "my_program" with an argument.
    
        PBS="#!/bin/bash\n\
        #PBS -N ${NAME}\n\
        #PBS -P ${nciproj}\n\
        #PBS -q copyq\n\
        #PBS -l ncpus=1\n\
        #PBS -l walltime=01:00:00\n\
        #PBS -l wd\n\
        #PBS -l storage=gdata/${nciproj}+gdata/rt52+gdata/uc16+gdata/hh5\n\
        #PBS -l mem=2GB\n\
        #PBS -e ${runpath}output/${NAME}.e\n\
        #PBS -o ${runpath}output/${NAME}.o\n\
    
    	module use /g/data/hh5/public/modules\n\
    	module load conda/analysis3-24.01\n\
    	
    	cd ${runpath}\n\
        python3 get_GFS.py ${date} ${run} ${day}"
    
        # Echo the string PBS to the function qsub, which submits it as a cluster job for you
        # A small delay is included to avoid overloading the submission process
    
        echo -e ${PBS} | qsub
        sleep 0.5
        echo "Complete."
    done
    
    MAX_WAIT_TIME=3600
    
    # Start time
    START_TIME=$(date +%s)
    
    for day in $RANGE;
    do
        # Path to the file to check
        FILE_PATH="$outpath/get_GFS_d${day}.check"
        
        # Wait until the file exists
        while [ ! -f "$FILE_PATH" ]; do
            echo "Waiting for $FILE_PATH to be created..."
            sleep 30  # Wait for 1 second before checking again
        done
    
        CURRENT_TIME=$(date +%s)
        ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
    
        if [ $ELAPSED_TIME -ge $MAX_WAIT_TIME ]; then
            echo "File $FILE_PATH did not appear within the maximum wait time of 1 hour."
            exit 1
        fi
    done
else
    echo "Skipping data download."
fi

if [ "$run_plotting" = true ]; then
    
    rm -f "${outpath}images/"*.jpg
    
    for tstep in $plotRANGE;
    do
        # set the job name
        NAME="plot_GFS-t"${tstep}
        echo "Submitting: ${NAME}"
    
        # Build a string called PBS which contains the instructions for your run
        # This requests 1 node for 1 hour. Runs a program called "my_program" with an argument.
    
        PBS="#!/bin/bash\n\
        #PBS -N ${NAME}\n\
        #PBS -P ${nciproj}\n\
        #PBS -q normal\n\
        #PBS -l ncpus=4\n\
        #PBS -l walltime=02:30:00\n\
        #PBS -l wd\n\
        #PBS -l storage=gdata/gb02+gdata/rt52+gdata/uc16+gdata/hh5\n\
        #PBS -l mem=8GB\n\
        #PBS -e ${runpath}output/${NAME}.e\n\
        #PBS -o ${runpath}output/${NAME}.o\n\
    
    	module use /g/data/hh5/public/modules\n\
    	module load conda/analysis3-24.01\n\
    	
    	cd ${runpath}\n\
        python3 plot_GFS.py ${date} ${run} ${tstep}"
    
        # Echo the string PBS to the function qsub, which submits it as a cluster job for you
        # A small delay is included to avoid overloading the submission process
    
        echo -e ${PBS} | qsub
        sleep 0.5
        echo "Complete."
    done
    
    MAX_WAIT_TIME=7200
    START_TIME=$(date +%s)
    
    for tstep in $plotRANGE;
    do
        # Path to the file to check
        FILE_PATH="$outpath/plot_GFS_t${tstep}.check"
        
        # Wait until the file exists
        while [ ! -f "$FILE_PATH" ]; do
            echo "Waiting for $FILE_PATH to be created..."
            sleep 60  # Wait for 1 second before checking again
        done
    
        CURRENT_TIME=$(date +%s)
        ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
    
        if [ $ELAPSED_TIME -ge $MAX_WAIT_TIME ]; then
            echo "File $FILE_PATH did not appear within the maximum wait time of 1 hour."
            exit 1
        fi
    done

else
    echo "Skipping data download."
fi

if [ "$copy_to_bucket" = true ]; then
    # Use the range in a loop
    for day in {1..1};
    do
        # set the job name
        NAME="copy_GFS-all_SH"
        echo "Submitting: ${NAME}"
    
        # Build a string called PBS which contains the instructions for your run
        # This requests 1 node for 1 hour. Runs a program called "my_program" with an argument.
    
        PBS="#!/bin/bash\n\
        #PBS -N ${NAME}\n\
        #PBS -P ${nciproj}\n\
        #PBS -q copyq\n\
        #PBS -l ncpus=1\n\
        #PBS -l walltime=02:00:00\n\
        #PBS -l wd\n\
        #PBS -l storage=gdata/${nciproj}+gdata/rt52+gdata/uc16+gdata/hh5\n\
        #PBS -l mem=2GB\n\
        #PBS -e ${runpath}output/${NAME}.e\n\
        #PBS -o ${runpath}output/${NAME}.o\n\
    
    	module use /g/data/hh5/public/modules\n\
    	module load conda/analysis3-24.01\n\
    	
    	cd ${runpath}\n\
        python3 plot_GFS_copy_to_bucket.py ${date} ${run} SH"
    
        # Echo the string PBS to the function qsub, which submits it as a cluster job for you
        # A small delay is included to avoid overloading the submission process
    
        echo -e ${PBS} | qsub
        sleep 0.5
        echo "Complete."
    done
    
    # Use the range in a loop
    for day in {1..1};
    do
        # set the job name
        NAME="copy_GFS-all_NH"
        echo "Submitting: ${NAME}"
    
        # Build a string called PBS which contains the instructions for your run
        # This requests 1 node for 1 hour. Runs a program called "my_program" with an argument.
    
        PBS="#!/bin/bash\n\
        #PBS -N ${NAME}\n\
        #PBS -P ${nciproj}\n\
        #PBS -q copyq\n\
        #PBS -l ncpus=1\n\
        #PBS -l walltime=02:00:00\n\
        #PBS -l wd\n\
        #PBS -l storage=gdata/${nciproj}+gdata/rt52+gdata/uc16+gdata/hh5\n\
        #PBS -l mem=2GB\n\
        #PBS -e ${runpath}output/${NAME}.e\n\
        #PBS -o ${runpath}output/${NAME}.o\n\
    
    	module use /g/data/hh5/public/modules\n\
    	module load conda/analysis3-24.01\n\
    	
    	cd ${runpath}\n\
        python3 plot_GFS_copy_to_bucket.py ${date} ${run} NH"
    
        # Echo the string PBS to the function qsub, which submits it as a cluster job for you
        # A small delay is included to avoid overloading the submission process
    
        echo -e ${PBS} | qsub
        sleep 0.5
        echo "Complete."
    done
    
    MAX_WAIT_TIME=7200
    START_TIME=$(date +%s)
    
    for day in {1..1};
    do
        # Path to the file to check
        FILE_PATH="$outpath/copy_GFS_data_SH.check"
        
        # Wait until the file exists
        while [ ! -f "$FILE_PATH" ]; do
            echo "Waiting for $FILE_PATH to be created..."
            sleep 60  # Wait for 1 second before checking again
        done
    
        CURRENT_TIME=$(date +%s)
        ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
    
        if [ $ELAPSED_TIME -ge $MAX_WAIT_TIME ]; then
            echo "File $FILE_PATH did not appear within the maximum wait time of 1 hour."
            exit 1
        fi
    done
    
    MAX_WAIT_TIME=7200
    START_TIME=$(date +%s)
    
    for day in {1..1};
    do
        # Path to the file to check
        FILE_PATH="$outpath/copy_GFS_data_NH.check"
        
        # Wait until the file exists
        while [ ! -f "$FILE_PATH" ]; do
            echo "Waiting for $FILE_PATH to be created..."
            sleep 60  # Wait for 1 second before checking again
        done
    
        CURRENT_TIME=$(date +%s)
        ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
    
        if [ $ELAPSED_TIME -ge $MAX_WAIT_TIME ]; then
            echo "File $FILE_PATH did not appear within the maximum wait time of 1 hour."
            exit 1
        fi
    done
else
    echo "Skipping copy data to bucket."
fi


